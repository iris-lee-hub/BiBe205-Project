{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd65fdeb-3d43-475c-a1ab-2d153415d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyTDC in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (1.4.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (0.13.3)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (0.18.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (0.11.2)\n",
      "Requirement already satisfied: rdkit-pypi in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (2022.9.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (1.23.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (1.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (2.28.2)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from PyTDC) (0.8)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from huggingface-hub->PyTDC) (23.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from huggingface-hub->PyTDC) (3.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from huggingface-hub->PyTDC) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from huggingface-hub->PyTDC) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from tqdm->PyTDC) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from pandas->PyTDC) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from pandas->PyTDC) (2.8.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from rdkit-pypi->PyTDC) (9.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from requests->PyTDC) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from requests->PyTDC) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from requests->PyTDC) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from requests->PyTDC) (1.26.15)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from scikit-learn->PyTDC) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from scikit-learn->PyTDC) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from scikit-learn->PyTDC) (3.1.0)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from seaborn->PyTDC) (3.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from matplotlib>=2.2->seaborn->PyTDC) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from matplotlib>=2.2->seaborn->PyTDC) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from matplotlib>=2.2->seaborn->PyTDC) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from matplotlib>=2.2->seaborn->PyTDC) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danny\\anaconda3\\envs\\spyder_broke\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->PyTDC) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyTDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "869a3eea-d2c7-4403-b912-92ae27cbca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#import bokeh.io\n",
    "#import bokeh.plotting\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from tdc.multi_pred import PPI\n",
    "#from tqdm import tqdm\n",
    "\n",
    "ts = time.time()\n",
    "#bokeh.io.output_notebook()\n",
    "generator = torch.Generator().manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dcf6e3d-50ff-4a4d-b72d-c44bdf4f8306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = PPI(name = 'HuRI')\n",
    "data = data.neg_sample(frac = 1)\n",
    "split = data.get_split(frac=[0.8, 0, 0.2], seed=12)\n",
    "train_full = split['train']\n",
    "valid_full = split['valid']\n",
    "test_full = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37b733d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1988"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 100\n",
    "\n",
    "# remove data where protein sequences are longer than max_len amino acids\n",
    "train = train_full.loc[train_full[\"Protein1\"].str.len()<max_len]\n",
    "train = train_full.loc[train_full[\"Protein2\"].str.len()<max_len]\n",
    "# valid = valid_full.loc[valid_full[\"Protein1\"].str.len()<max_len]\n",
    "# valid = valid_full.loc[valid_full[\"Protein2\"].str.len()<max_len]\n",
    "# test = test_full.loc[test_full[\"Protein1\"].str.len()<max_len]\n",
    "# test = test_full.loc[test_full[\"Protein2\"].str.len()<max_len]\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "309aff5a-24e3-4fe5-b117-734da5a3195d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein1_ID</th>\n",
       "      <th>Protein1</th>\n",
       "      <th>Protein2_ID</th>\n",
       "      <th>Protein2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>ENSG00000002726</td>\n",
       "      <td>MPALGWAVAAILMLQTAMAEPSPGTLPRKAGVFSDLSNQELKAVHS...</td>\n",
       "      <td>ENSG00000183640</td>\n",
       "      <td>MLCDNFPGAVFPGCYWGSYGYPLGYSVGCGYGSTYSPVGYGFGYGY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>ENSG00000002834</td>\n",
       "      <td>MNPNCARCGKIVYPTEKVNCLDKFWHKACFHCETCKMTLNMKNYKG...</td>\n",
       "      <td>ENSG00000186925</td>\n",
       "      <td>MRYYGSYYRGLGYGCGGFGGLGYGCGCGGYRYGSGYGGYRYGCCRP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Protein1_ID                                           Protein1  \\\n",
       "74   ENSG00000002726  MPALGWAVAAILMLQTAMAEPSPGTLPRKAGVFSDLSNQELKAVHS...   \n",
       "150  ENSG00000002834  MNPNCARCGKIVYPTEKVNCLDKFWHKACFHCETCKMTLNMKNYKG...   \n",
       "\n",
       "         Protein2_ID                                           Protein2  Y  \n",
       "74   ENSG00000183640  MLCDNFPGAVFPGCYWGSYGYPLGYSVGCGYGSTYSPVGYGFGYGY...  1  \n",
       "150  ENSG00000186925  MRYYGSYYRGLGYGCGGFGGLGYGCGCGGYRYGSGYGGYRYGCCRP...  1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed04eac0-930c-4d0a-b8ce-f9155fbb19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = 'MLASGVEKITDRPNFQYHCW'\n",
    "aatoidx = {}\n",
    "for i, amino_acid in enumerate(amino_acids):\n",
    "    aatoidx[amino_acid] = i+1\n",
    "\n",
    "p1 = []\n",
    "p2 = []\n",
    "labs = []\n",
    "for row in range(train.shape[0]):\n",
    "    r = train.iloc[row]\n",
    "    protein1 = r['Protein1']\n",
    "    protein2 = r['Protein2']\n",
    "    prot1 = []\n",
    "    prot2 = []\n",
    "    add = True\n",
    "    for i in range(max_len):\n",
    "        if i < len(protein1)-1:\n",
    "            if protein1[i] in amino_acids:\n",
    "                prot1.append(aatoidx[protein1[i]])\n",
    "            else:\n",
    "                add = False\n",
    "                break\n",
    "        else:\n",
    "            prot1.append(0)\n",
    "            \n",
    "        if i < len(protein2)-1:\n",
    "            if protein2[i] in amino_acids:\n",
    "                prot2.append(aatoidx[protein2[i]])\n",
    "            else:\n",
    "                add = False\n",
    "                break\n",
    "        else:\n",
    "            prot2.append(0)\n",
    "        \n",
    "    if add:\n",
    "        p1.append(torch.tensor(prot1).type(torch.long))\n",
    "        p2.append(torch.tensor(prot2).type(torch.long))\n",
    "        labs.append(r['Y'])\n",
    "\n",
    "p1 = torch.stack(p1)\n",
    "#p1 = F.one_hot(p1, num_classes=21)[:,:,1:].type(torch.float)\n",
    "p1 = p1 / 20\n",
    "p2 = torch.stack(p2)\n",
    "#p2 = F.one_hot(p2, num_classes=21)[:,:,1:].type(torch.float)\n",
    "p2 = p2 / 20\n",
    "labs = torch.tensor(labs).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b3ae442-4fd7-4c6c-a3cf-da519e9161ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HuRI(Dataset):\n",
    "    def __init__(self, labs, p1, p2):\n",
    "        # labs is an (n_samples,)-long torch tensor of 0/1 interaction scores\n",
    "        # prot1 is an (n_samples, max_len, 20)-shaped torch tensor of one-hot encoded protein 1s\n",
    "        # prot2 is an (n_samples, max_len, 20)-shaped torch tensor of one-hot encoded protein 2s\n",
    "        self.labs = labs\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #return (self.p1[idx,:,:], self.p2[idx,:,:]), self.labs[idx]\n",
    "        label = torch.zeros(2)\n",
    "        label[self.labs[idx].type(torch.long)] = 1\n",
    "        return (self.p1[idx,:], self.p2[idx,:]), label.type(torch.float) #self.labs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d4b1362-a614-44f0-a643-7e39f9d4f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c = 256\n",
    "        self.InputConv = nn.Conv1d(2, self.c, 5, padding='valid').to(device)\n",
    "        self.BasicConv = nn.Conv1d(int(self.c/2), self.c, 5, padding='same').to(device)\n",
    "        self.EndConv1 = nn.Conv1d(int(self.c/2), 3, 1).to(device)\n",
    "        self.EndConv2 = nn.Conv1d(3, 2, 1).to(device)\n",
    "        self.Lin1 = nn.Linear(max_len*2 - 8, 64).to(device)\n",
    "        self.Lin2 = nn.Linear(64, 2).to(device)\n",
    "    \n",
    "    def forward(self, p1, p2):\n",
    "        x = self.InputConv(torch.stack((p1, p2), dim=1))\n",
    "        for i in range(20):\n",
    "            x = self.BasicConv(F.glu(F.layer_norm(x, x.shape[1:]), dim=1)) + x\n",
    "        x = self.BasicConv(F.glu(F.layer_norm(x, x.shape[1:]), dim=1))\n",
    "        for i in range(20):\n",
    "            x = self.BasicConv(F.glu(F.layer_norm(x, x.shape[1:]), dim=1)) + x\n",
    "        x = F.glu(F.layer_norm(x, x.shape[1:]), dim=1)\n",
    "        x = self.EndConv1(x)\n",
    "        x = self.EndConv2(x).flatten(start_dim=1)\n",
    "        x = F.relu(self.Lin1(F.dropout(x, p=0.4)))\n",
    "        x = self.Lin2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbb69568-ddc5-435e-b139-eafcc0a5b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running with {device}')\n",
    "\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "#torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b207585-ba2d-478b-9109-72735f061c15",
   "metadata": {
    "id": "lf0i2bh2QFwI"
   },
   "outputs": [],
   "source": [
    "dataset = HuRI(labs, p1, p2)\n",
    "\n",
    "train_test = random_split(dataset, [int(labs.shape[0]*0.8), \n",
    "                                    labs.shape[0]-int(labs.shape[0]*0.8)],\n",
    "                          generator=generator)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_test[0], batch_size=batch_size, shuffle=True, generator=generator)\n",
    "test_loader = DataLoader(train_test[1], batch_size=batch_size, shuffle=False, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fefe0e5a-dd48-4ee2-84aa-2e4a80c6b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = ConvolutionalClassifier()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d76ddbc-dbfc-4089-842b-ab3b589eb024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t Accuracy: 54.73684\tTrain Loss: 0.90379\tTest Loss: 0.88954\tRuntime: 44.0\n",
      "Epoch 2:\t Accuracy: 53.94737\tTrain Loss: 0.85319\tTest Loss: 0.85342\tRuntime: 38.0\n",
      "Epoch 3:\t Accuracy: 55.0\tTrain Loss: 0.81548\tTest Loss: 0.80277\tRuntime: 41.0\n",
      "Epoch 4:\t Accuracy: 57.10526\tTrain Loss: 0.76909\tTest Loss: 0.76983\tRuntime: 50.0\n",
      "Epoch 5:\t Accuracy: 56.31579\tTrain Loss: 0.74265\tTest Loss: 0.73772\tRuntime: 32.0\n",
      "Epoch 6:\t Accuracy: 56.31579\tTrain Loss: 0.71058\tTest Loss: 0.74835\tRuntime: 38.0\n",
      "Epoch 7:\t Accuracy: 56.05263\tTrain Loss: 0.69209\tTest Loss: 0.73827\tRuntime: 38.0\n",
      "Epoch 8:\t Accuracy: 54.47369\tTrain Loss: 0.68359\tTest Loss: 0.73203\tRuntime: 40.0\n",
      "Epoch 9:\t Accuracy: 55.26316\tTrain Loss: 0.66099\tTest Loss: 0.71635\tRuntime: 32.0\n",
      "Epoch 10:\t Accuracy: 53.68421\tTrain Loss: 0.64274\tTest Loss: 0.72423\tRuntime: 38.0\n",
      "Epoch 11:\t Accuracy: 55.26316\tTrain Loss: 0.6413\tTest Loss: 0.72835\tRuntime: 46.0\n",
      "Epoch 12:\t Accuracy: 55.26316\tTrain Loss: 0.62157\tTest Loss: 0.72044\tRuntime: 41.0\n",
      "Epoch 13:\t Accuracy: 56.05263\tTrain Loss: 0.61943\tTest Loss: 0.70608\tRuntime: 38.0\n",
      "Epoch 14:\t Accuracy: 55.26316\tTrain Loss: 0.60061\tTest Loss: 0.71953\tRuntime: 42.0\n",
      "Epoch 15:\t Accuracy: 55.26316\tTrain Loss: 0.58463\tTest Loss: 0.72564\tRuntime: 44.0\n",
      "Epoch 16:\t Accuracy: 55.0\tTrain Loss: 0.58784\tTest Loss: 0.71591\tRuntime: 38.0\n",
      "Epoch 17:\t Accuracy: 54.21052\tTrain Loss: 0.5865\tTest Loss: 0.72077\tRuntime: 41.0\n",
      "Epoch 18:\t Accuracy: 53.42105\tTrain Loss: 0.583\tTest Loss: 0.72427\tRuntime: 39.0\n",
      "Epoch 19:\t Accuracy: 55.52632\tTrain Loss: 0.56768\tTest Loss: 0.73862\tRuntime: 38.0\n",
      "Epoch 20:\t Accuracy: 55.0\tTrain Loss: 0.57243\tTest Loss: 0.73151\tRuntime: 58.0\n",
      "Training Runtime: 817.3933382034302s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "train_loss_tracker = torch.zeros(num_epochs)\n",
    "test_loss_tracker = torch.zeros(num_epochs)\n",
    "\n",
    "tic = time.time()\n",
    "#print(f'Setup Time: {tic - ts}')\n",
    "te = tic\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs): #tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for i, (train_data, train_labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(train_data[0].to(device), train_data[1].to(device)).to(device)\n",
    "        probs, preds = torch.max(outputs, dim=1)\n",
    "        train_labels = train_labels.to(device)\n",
    "        loss = loss_fn(outputs, train_labels)\n",
    "        train_loss_tracker[epoch] += loss / (int(labs.shape[0]*0.8)*torch.log(torch.tensor(4)))\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (test_data, test_labels) in enumerate(test_loader):\n",
    "            outputs = model(test_data[0].to(device), test_data[1].to(device)).to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "            test_loss = loss_fn(outputs, test_labels)\n",
    "            test_loss_tracker[epoch] += test_loss / \\\n",
    "                    ((labs.shape[0]-int(labs.shape[0]*0.8))*torch.log(torch.tensor(4)))\n",
    "            ps, preds = torch.max(outputs, dim=1)\n",
    "            acc += sum(preds == test_labels.argmax()) / (labs.shape[0]-int(labs.shape[0]*0.8))\n",
    "    \n",
    "    scheduler.step(acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}:\\t Accuracy: {round(acc.item()*100, 5)}', end='')\n",
    "    print(f'\\tTrain Loss: {round(train_loss_tracker[epoch].item(), 5)}', end='')\n",
    "    print(f'\\tTest Loss: {round(test_loss_tracker[epoch].item(), 5)}', end='')\n",
    "    print(f'\\tRuntime: {round(time.time()-te, 0)}')\n",
    "    te = time.time()\n",
    "    \n",
    "toc = time.time()\n",
    "print(f'Training Runtime: {toc-tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d2c8e-594f-4f42-a069-5330882f755e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
