{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869a3eea-d2c7-4403-b912-92ae27cbca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from tdc.multi_pred import PPI\n",
    "from tqdm import tqdm\n",
    "\n",
    "ts = time.time()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dcf6e3d-50ff-4a4d-b72d-c44bdf4f8306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = PPI(name = 'HuRI')\n",
    "data = data.neg_sample(frac = 1)\n",
    "split = data.get_split()\n",
    "train = split['train']\n",
    "valid = split['valid']\n",
    "test = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b733d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data where protein sequences are longer than 800 amino acids\n",
    "train = train.loc[train[\"Protein1\"].str.len()<1000]\n",
    "train = train.loc[train[\"Protein2\"].str.len()<1000]\n",
    "# valid = valid.loc[valid[\"Protein1\"].str.len()<1000]\n",
    "# valid = valid.loc[valid[\"Protein2\"].str.len()<1000]\n",
    "# test = test.loc[test[\"Protein1\"].str.len()<1000]\n",
    "# test = test.loc[test[\"Protein2\"].str.len()<1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309aff5a-24e3-4fe5-b117-734da5a3195d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein1_ID</th>\n",
       "      <th>Protein1</th>\n",
       "      <th>Protein2_ID</th>\n",
       "      <th>Protein2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>MAKNPPENCEDCHILNAEAFKSKKICKSLKICGLVFGILALTLIVL...</td>\n",
       "      <td>ENSG00000061656</td>\n",
       "      <td>MRRSSRPGSASSSRKHTPNFFSENSSMSITSEDSKGLRSAEPGPGE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>MAKNPPENCEDCHILNAEAFKSKKICKSLKICGLVFGILALTLIVL...</td>\n",
       "      <td>ENSG00000104765</td>\n",
       "      <td>MSSHLVEPPPPLHNNNNNCEENEQSLPPPAGLNSSWVELPMNSSNG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protein1_ID                                           Protein1  \\\n",
       "0  ENSG00000000005  MAKNPPENCEDCHILNAEAFKSKKICKSLKICGLVFGILALTLIVL...   \n",
       "1  ENSG00000000005  MAKNPPENCEDCHILNAEAFKSKKICKSLKICGLVFGILALTLIVL...   \n",
       "\n",
       "       Protein2_ID                                           Protein2  Y  \n",
       "0  ENSG00000061656  MRRSSRPGSASSSRKHTPNFFSENSSMSITSEDSKGLRSAEPGPGE...  1  \n",
       "1  ENSG00000104765  MSSHLVEPPPPLHNNNNNCEENEQSLPPPAGLNSSWVELPMNSSNG...  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc67f70-34b7-4edf-a0bb-0fede84d1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "aatoidx = {}\n",
    "i = 1\n",
    "skip = False\n",
    "for p1 in train['Protein1']:\n",
    "    for c1 in p1:\n",
    "        if c1 not in aatoidx.keys():\n",
    "            aatoidx[c1] = i\n",
    "            i += 1\n",
    "    if i == 24:\n",
    "        skip = True\n",
    "        break\n",
    "if not skip:\n",
    "    for p2 in train['Protein2']:\n",
    "        for c2 in p2:\n",
    "            if c1 not in aatoidx.keys():\n",
    "                aatoidx[c1] = i\n",
    "                i += 1\n",
    "        if i == 23:\n",
    "            break\n",
    "aatoidx['0'] = 0\n",
    "\n",
    "idxtoaa = {}\n",
    "for key in aatoidx.keys():\n",
    "    idxtoaa[aatoidx[key]] = key\n",
    "    \n",
    "aato1hot = {}\n",
    "for aa in aatoidx.keys():\n",
    "    aato1hot[aa] = F.one_hot(torch.tensor(aatoidx[aa]), num_classes=len(aatoidx))\n",
    "aato1hot['0'] = torch.cat((torch.tensor(1).unsqueeze(-1), torch.zeros(23))).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf39553b-b738-43a7-b204-4f3ba0994885",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1000\n",
    "\n",
    "aa1 = torch.empty((len(train['Protein1']), max_len, len(aato1hot)))\n",
    "aa2 = torch.empty((len(train['Protein2']), max_len, len(aato1hot)))\n",
    "for p in range(len(train['Protein1'])):\n",
    "    prot1 = train['Protein1'].iloc[p]\n",
    "    prot2 = train['Protein2'].iloc[p]\n",
    "    for i in range(max_len):\n",
    "        if i < len(prot1):\n",
    "            aa1[p,i,:] = aato1hot[prot1[i]]\n",
    "        else:\n",
    "            aa1[p,i,:] = aato1hot['0']\n",
    "        if i < len(prot2):\n",
    "            aa2[p,i,:] = aato1hot[prot2[i]]\n",
    "        else:\n",
    "            aa2[p,i,:] = aato1hot['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8fb172c-32ee-4dfd-b8e6-46e9d33c4118",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aa1 = [[aatoidx[s[i]] if i < len(s) else 0 for i in range(1000)] for s in train['Protein1']]\n",
    "# aa2 = [[aatoidx[s[i]] if i < len(s) else 0 for i in range(1000)] for s in train['Protein2']]\n",
    "# aav1 = [[aatoidx[s[i]] if i < len(s) else 0 for i in range(800)] for s in valid['Protein1']]\n",
    "# aav2 = [[aatoidx[s[i]] if i < len(s) else 0 for i in range(800)] for s in valid['Protein2']]\n",
    "# aat1 = [[aatoidx[s[i]] if i < len(s) else 0 for i in range(800)] for s in test['Protein1']]\n",
    "# aat2 = [[aatoidx[s[i]] if i < len(s) else 0 for i in range(800)] for s in test['Protein2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "390aa228-d0e9-4e77-9918-240284eb54f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24694, 24694)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa1), len(aa2) #, len(aav1), len(aav2), len(aat1), len(aat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22ea00ae-c393-4e9e-9636-5ac2b90cf903",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min protein lengths:\n",
      "\tTrain 1: 1000\n",
      "\tTrain 2: 1000\n",
      "\tValid 1: 36\n",
      "\tValid 2: 36\n",
      "\tTest 1: 26\n",
      "\tTest 2: 26\n",
      "Mean protein lengths:\n",
      "\tTrain 1: 1000.0\n",
      "\tTrain 2: 1000.0\n",
      "\tValid 1: 1382.5512698109605\n",
      "\tValid 2: 1342.351346190567\n",
      "\tTest 1: 1403.1202978804658\n",
      "\tTest 2: 1343.2868531602062\n",
      "Max protein lengths:\n",
      "\tTrain 1: 1000\n",
      "\tTrain 2: 1000\n",
      "\tValid 1: 29856\n",
      "\tValid 2: 33472\n",
      "\tTest 1: 33472\n",
      "\tTest 2: 27986\n"
     ]
    }
   ],
   "source": [
    "# print('Min protein lengths:')\n",
    "# print('\\tTrain 1:', min([len(s) for s in aa1]))\n",
    "# print('\\tTrain 2:', min([len(s) for s in aa2]))\n",
    "# print('\\tValid 1:', min([len(s) for s in aav1]))\n",
    "# print('\\tValid 2:', min([len(s) for s in aav2]))\n",
    "# print('\\tTest 1:', min([len(s) for s in aat1]))\n",
    "# print('\\tTest 2:', min([len(s) for s in aat2]))\n",
    "# print('Mean protein lengths:')\n",
    "# print('\\tTrain 1:', sum([len(s) for s in aa1])/len(aa1))\n",
    "# print('\\tTrain 2:', sum([len(s) for s in aa2])/len(aa2))\n",
    "# print('\\tValid 1:', sum([len(s) for s in aav1])/len(aav1))\n",
    "# print('\\tValid 2:', sum([len(s) for s in aav2])/len(aav2))\n",
    "# print('\\tTest 1:', sum([len(s) for s in aat1])/len(aat1))\n",
    "# print('\\tTest 2:', sum([len(s) for s in aat2])/len(aat2))\n",
    "# print('Max protein lengths:')\n",
    "# print('\\tTrain 1:', max([len(s) for s in aa1]))\n",
    "# print('\\tTrain 2:', max([len(s) for s in aa2]))\n",
    "# print('\\tValid 1:', max([len(s) for s in aav1]))\n",
    "# print('\\tValid 2:', max([len(s) for s in aav2]))\n",
    "# print('\\tTest 1:', max([len(s) for s in aat1]))\n",
    "# print('\\tTest 2:', max([len(s) for s in aat2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62f9582b-443b-4b7e-bbd5-90835e7c7c6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lens1 = [len(aa1[i]) for i in range(len(aa1))]\n",
    "# lens2 = [len(aa2[i]) for i in range(len(aa2))]\n",
    "# lensv1 = [len(aav1[i]) for i in range(len(aav1))]\n",
    "# lensv2 = [len(aav2[i]) for i in range(len(aav2))]\n",
    "# lenst1 = [len(aat1[i]) for i in range(len(aat1))]\n",
    "# lenst2 = [len(aat2[i]) for i in range(len(aat2))]\n",
    "# lens1.sort()\n",
    "# lens2.sort()\n",
    "# lensv1.sort()\n",
    "# lensv2.sort()\n",
    "# lenst1.sort()\n",
    "# lenst2.sort()\n",
    "\n",
    "# p = bokeh.plotting.figure(title='Sequence Length CDFs', x_axis_type='log', y_axis_type='log')\n",
    "# p.line(lens1, [(i+1)/len(aa1) for i in range(len(aa1))],\n",
    "#        color='red', legend_label='Train 1', line_width=3, alpha=0.5)\n",
    "# p.line(lens2, [(i+1)/len(aa2) for i in range(len(aa2))],\n",
    "#        color='orange', legend_label='Train 2', line_width=3, alpha=0.5)\n",
    "# p.line(lensv1, [(i+1)/len(aav1) for i in range(len(aav1))],\n",
    "#        color='green', legend_label='Valid 1', line_width=3, alpha=0.5)\n",
    "# p.line(lensv2, [(i+1)/len(aav2) for i in range(len(aav2))],\n",
    "#        color='cyan', legend_label='Valid 2', line_width=3, alpha=0.5)\n",
    "# p.line(lenst1, [(i+1)/len(aat1) for i in range(len(aat1))],\n",
    "#        color='blue', legend_label='Test 1', line_width=3, alpha=0.5)\n",
    "# p.line(lenst2, [(i+1)/len(aat2) for i in range(len(aat2))],\n",
    "#        color='purple', legend_label='Test 2', line_width=3, alpha=0.5)\n",
    "# p.legend.location = 'top_left'\n",
    "# bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3ae442-4fd7-4c6c-a3cf-da519e9161ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HuRI(Dataset):\n",
    "    def __init__(self, labels, p1s, p2s):\n",
    "        # labels is an (n_samples,)-long ndarray\n",
    "        # p1s is a list of lists of integers representing protein 1 amino acids\n",
    "        # p2s is a list of lists of integers representing protein 2 amino acids\n",
    "        self.labels = labels\n",
    "        self.p1s = p1s\n",
    "        self.p2s = p2s\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.p1s[idx]).type(torch.float), \n",
    "                torch.tensor(self.p2s[idx]).type(torch.float)), \\\n",
    "               torch.tensor(self.labels.iloc[idx]).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb69568-ddc5-435e-b139-eafcc0a5b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running on {device}')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b207585-ba2d-478b-9109-72735f061c15",
   "metadata": {
    "id": "lf0i2bh2QFwI"
   },
   "outputs": [],
   "source": [
    "labels = train['Y']\n",
    "\n",
    "data = HuRI(labels, aa1, aa2)\n",
    "\n",
    "train_test = random_split(data, [int(labels.shape[0]*0.8), labels.shape[0]-int(labels.shape[0]*0.8)])\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_test[0], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(train_test[1], batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f098d4fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels = test['Y']\n",
    "\n",
    "# data = HuRI(labels, aat1, aat2)\n",
    "\n",
    "# batch_size = 18282\n",
    "# test_loader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7746b6e-cb45-4895-b0e0-84a8e767c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(0,0,1)\n",
    "    \n",
    "    def forward(self, p1, p2):\n",
    "        return F.softmax(torch.randn(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3441be7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define the neural network model\n",
    "# class BinaryClassifier(nn.Module):\n",
    "#     def __init__(self, n_samples = 5):\n",
    "#         super(BinaryClassifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(800, n_samples)   # Input layer\n",
    "#         # Layers???\n",
    "#         self.fc2 = nn.Linear(800, n_samples)\n",
    "#         self.gelu = nn.GELU()\n",
    "#         self.fc3 = nn.Linear(10, 1)    \n",
    "#         self.sig = nn.Sigmoid() # Output layer        \n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         out1 = self.gelu(self.fc1(x1))\n",
    "#         out2 = self.gelu(self.fc2(x2))\n",
    "#         out = torch.cat((out1, out2), dim=1)\n",
    "#         out = self.fc3(out)\n",
    "#         out = self.sig(out)\n",
    "\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fefe0e5a-dd48-4ee2-84aa-2e4a80c6b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = ConvolutionalClassifier()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4)\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d76ddbc-dbfc-4089-842b-ab3b589eb024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Time: 1719.8332335948944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20948\\2954124629.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mtrain_loss_tracker\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Backward and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\spyder_broke\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\spyder_broke\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\spyder_broke\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3072\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3073\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3074\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   3075\u001b[0m             \u001b[1;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3076\u001b[0m             \u001b[1;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "train_loss_tracker = np.zeros(num_epochs)\n",
    "test_loss_tracker = np.zeros(num_epochs)\n",
    "\n",
    "tic = time.time()\n",
    "print(f'Setup Time: {tic - ts}')\n",
    "te = tic\n",
    "\n",
    "# Train the model\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, (train_data, train_labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(train_data[0].to(device), train_data[1].to(device)).to(device)\n",
    "        train_labels = train_labels.unsqueeze(1).to(device)\n",
    "        train_loss_tracker[i] += loss_fn(outputs, train_labels) / len(train_test[0].shape[0])\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                                                                      \n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (test_data, test_labels) in enumerate(test_loader):\n",
    "            outputs = model(test_data[0].to(device), test_data[1].to(device)).to(device)\n",
    "            test_labels = test_labels.unsqueeze(1).to(device)\n",
    "            test_loss_tracker[i] += loss_fn(outputs, test_labels) / train_test[1].shape[0]\n",
    "            ps, preds = torch.max(outputs)\n",
    "            acc += sum(preds == test_labels) / train_test[1].shape[0]\n",
    "    print(f'Epoch {epoch+1} Accuracy: {acc*100},\\tTrain Loss: {train_loss},', end='')\n",
    "    print(f'\\tTest Loss: {test_loss},\\tRuntime: {time.time()-te}')\n",
    "    te = time.time()\n",
    "    \n",
    "toc = time.time()\n",
    "print(f'Training Runtime: {toc-tic}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
