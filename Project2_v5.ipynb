{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "KEHYOqlkZytB",
    "outputId": "c7d1b002-db10-4bba-a24e-5151c92450f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyTDC in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (0.3.8)\n",
      "Requirement already satisfied: rdkit-pypi in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (2022.9.5)\n",
      "Requirement already satisfied: fuzzywuzzy in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (0.18.0)\n",
      "Requirement already satisfied: numpy in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (1.24.3)\n",
      "Requirement already satisfied: pandas in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (1.5.3)\n",
      "Requirement already satisfied: tqdm in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (1.2.2)\n",
      "Requirement already satisfied: seaborn in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (0.12.2)\n",
      "Requirement already satisfied: requests in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from PyTDC) (2.29.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from pandas->PyTDC) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from pandas->PyTDC) (2023.3)\n",
      "Requirement already satisfied: Pillow in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from rdkit-pypi->PyTDC) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from requests->PyTDC) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from requests->PyTDC) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from requests->PyTDC) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from requests->PyTDC) (2023.5.7)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from scikit-learn->PyTDC) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from scikit-learn->PyTDC) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from scikit-learn->PyTDC) (3.1.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from seaborn->PyTDC) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in ./mambaforge/envs/bebi205/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->PyTDC) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install PyTDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KyD2nywsZstI"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "from tdc.multi_pred import PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KyD2nywsZstI"
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "generator = torch.Generator().manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDLjPvQTZ-js",
    "outputId": "7fe7707f-8e86-4ca1-e63f-c174a849ffa9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = PPI(name = 'HuRI')\n",
    "data = data.neg_sample(frac = 1)\n",
    "split = data.get_split(frac=[0.8, 0, 0.2], seed=12)\n",
    "train_full = split['train']\n",
    "valid_full = split['valid']\n",
    "test_full = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "THak1GV618Nn"
   },
   "outputs": [],
   "source": [
    "amino_acids = 'ARNDCEQGHILKMFPSTWYVX'\n",
    "hydro = [1.8, -4.5, -3.5, -3.5, 2.5, -3.5, -3.5, -0.4, -3.2, 4.5, 3.8, -3.9,\n",
    "         1.9, 2.8, -1.6, -0.8, -0.7, -0.9, -1.3, 4.2, -0.49]\n",
    "hydro = (np.array(hydro) - np.mean(hydro)) / np.std(hydro)\n",
    "mass = [89.1, 174.2, 132.12, 133.11, 121.16, 147.13, 146.15,\n",
    "        75.07, 155.16, 131.18, 131.18, 146.19, 149.21, 165.19,\n",
    "        115.13, 105.09, 119.12, 204.23, 181.19, 117.15, 136.9]\n",
    "mass = (np.array(mass) - np.mean(mass)) / np.std(mass)\n",
    "volume = [88.6, 173.4, 114.1, 111.1, 108.5, 138.4, 143.8,\n",
    "          60.1, 153.2, 166.7, 166.7, 168.6, 162.9, 189.9,\n",
    "          112.7, 89, 116.1, 227.8, 193.6, 140, 141.3]\n",
    "volume = (np.array(volume) - np.mean(volume)) / np.std(volume)\n",
    "pka = [2.34, 2.17, 2.02, 1.88, 1.96, 2.19, 2.17,\n",
    "       2.34, 1.82, 2.36, 2.36, 2.18, 2.28, 1.83,\n",
    "       1.99, 2.21, 2.09, 2.83, 2.20, 2.32, 2.18]\n",
    "pka = (np.array(pka) - np.mean(pka)) / np.std(pka)\n",
    "pkb = [9.69, 9.04, 8.8, 9.6, 10.28, 9.67, 9.13, 9.6, 9.17, 9.6, 9.6, \n",
    "       8.95, 9.21, 9.13, 10.6, 9.15, 9.1, 9.39, 9.11, 9.62, 9.42]\n",
    "pkb = (np.array(pkb) - np.mean(pkb)) / np.std(pkb)\n",
    "pki = [6, 10.76, 5.41, 2.77, 5.07, 3.22, 5.65, 5.97, 7.59, 6.02, 5.98,\n",
    "       9.74, 5.74, 5.48, 6.3, 5.68, 5.6, 5.89, 5.66, 5.96, 6.02]\n",
    "pki = (np.array(pki) - np.mean(pki)) / np.std(pki)\n",
    "charge = np.array([0,1,0,-1,0,0,-1,0,1,0,0,1,0,0,0,0,0,0,0,0,0])\n",
    "polar = np.array([0,1,1,1,0,1,1,0,1,0,0,1,0,0,0,1,1,0,1,0,0.5])\n",
    "Hdonor = np.array([0,-1,0,1,0,0,1,0,0,0,0,-1,0,0,0,0,0,-1,0,0,0])\n",
    "freq = np.array([0.0777, 0.0627, 0.0336, 0.0524, 0.0078, 0.0315, 0.0859,\n",
    "                 0.073, 0.0192, 0.0666, 0.0891, 0.0776, 0.0241, 0.0361, \n",
    "                 0.0435, 0.0466, 0.0487, 0.0102, 0.03, 0.0817, 0.05])\n",
    "Pconserved = np.array([0.2063, 0.25, 0.1733, 0.262, 0.4095, 0.2244, 0.2960,\n",
    "                 0.3848, 0.1874, 0.2212, 0.397, 0.2986, 0.1772, 0.3914,\n",
    "                 0.3373, 0.1689, 0.1771, 0.6068, 0.4085, 0.2338, 0.2906])\n",
    "\n",
    "aadata = np.stack([hydro, mass, volume, pka, pkb, pki, charge,\n",
    "                               polar, Hdonor, freq, Pconserved], axis=1)\n",
    "\n",
    "aatoidx = {}\n",
    "for i, amino_acid in enumerate(amino_acids):\n",
    "    aatoidx[amino_acid] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CPO6tTdQu-Mo"
   },
   "outputs": [],
   "source": [
    "# min_len = 8297\n",
    "# max_len = 33472\n",
    "\n",
    "# Protein1 = train_full.Protein1\n",
    "# Protein2 = train_full.Protein2\n",
    "# Label = train_full.Y\n",
    "# p1 = []\n",
    "# p2 = []\n",
    "# labs = []\n",
    "# for idx in train_full.index:\n",
    "#     prot1 = Protein1.loc[idx].replace('*','')\n",
    "#     prot2 = Protein2.loc[idx].replace('*','')\n",
    "#     y = Label.loc[idx]\n",
    "#     nprot1 = []\n",
    "#     nprot2 = []\n",
    "#     add = True\n",
    "#     if len(prot1) <= max_len and len(prot2) <= max_len:\n",
    "#         if len(prot1) >= min_len and len(prot2) >= min_len:\n",
    "#             for i in range(max_len):\n",
    "#                 if i < len(prot1):\n",
    "#                     if prot1[i] in amino_acids:\n",
    "#                         nprot1.append(np.concatenate((\n",
    "#                                 aadata[aatoidx[prot1[i]],:], \n",
    "#                                 np.array([float(i)/len(prot1)]))))\n",
    "#                     else:\n",
    "#                         add = False\n",
    "#                         break\n",
    "#                 else:\n",
    "#                     nprot1.append(np.array([0,0,0,0,0,0,0,0,0,0,0,0]))\n",
    "#                 if i < len(prot2):\n",
    "#                     if prot2[i] in amino_acids:\n",
    "#                         nprot2.append(np.concatenate((\n",
    "#                                 aadata[aatoidx[prot2[i]],:], \n",
    "#                                 np.array([float(i)/len(prot2)]))))\n",
    "#                     else:\n",
    "#                         add = False\n",
    "#                         break\n",
    "#                 else:\n",
    "#                     nprot2.append(np.array([0,0,0,0,0,0,0,0,0,0,0,0]))\n",
    "#             if add:\n",
    "#                 p1.append(torch.tensor(nprot1).type(torch.long))\n",
    "#                 p2.append(torch.tensor(nprot2).type(torch.long))\n",
    "#                 labs.append(y)\n",
    "\n",
    "# p1 = torch.stack(p1).type(torch.float)\n",
    "# p2 = torch.stack(p2).type(torch.float)\n",
    "# labs = torch.tensor(labs).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 3268\n",
    "p1 = torch.load('p1_1663_3268.pt')\n",
    "p2 = torch.load('p2_1663_3268.pt')\n",
    "labs = torch.load('labs_1663_3268.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QitQ1w3YE8yh",
    "outputId": "b73e9342-90ec-4d5f-a00c-fa449fcbf35c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2597, 3268, 12]),\n",
       " torch.Size([2597, 3268, 12]),\n",
       " torch.Size([2597]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.shape, p2.shape, labs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-j8PUQlac0t",
    "outputId": "7bfdc7cb-573c-4586-d88d-dba9c33d83d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running with {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wai--2fvdb62"
   },
   "outputs": [],
   "source": [
    "class HuRI2d(Dataset):\n",
    "    def __init__(self, labs, p1, p2, loss_fn):\n",
    "        # labs is an (n_samples,)-long torch tensor of 0/1 interaction scores\n",
    "        # prot1 is an (n_samples, max_len, n_feats)-shaped tensor of protein 1 data\n",
    "        # prot2 is an (n_samples, max_len, n_feats)-shaped tensor of protein 2 data\n",
    "        # loss_fn is one of 'BCE', 'Cross', 'KLDiv', 'SoftMargin', or 'MSE'\n",
    "        self.labs = labs\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = torch.zeros(2)\n",
    "        label[self.labs[idx].type(torch.long)] = 1\n",
    "        if loss_fn == 'BCE' or loss_fn == 'Cross':\n",
    "            pass\n",
    "        elif loss_fn == 'SoftMargin' or loss_fn == 'MSE' or loss_fn == 'KLDiv':\n",
    "            for i in range(2):\n",
    "                if label[i] == 0:\n",
    "                    label[i] = -1\n",
    "        return (self.p1[idx,:,:], self.p2[idx,:,:]), label.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GKJ97McPc4uW"
   },
   "outputs": [],
   "source": [
    "class ConvolutionalClassifier2d(nn.Module):\n",
    "    def __init__(self, c, k, n):\n",
    "        super().__init__()\n",
    "        self.c = c\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.InputConv = nn.Conv2d(2, self.c, (self.k, 12), \n",
    "                                   padding='same').to(device)\n",
    "        self.BasicConvs = []\n",
    "        for i in range(2 * self.n):\n",
    "            self.BasicConvs.append(nn.Conv2d(int(self.c/2), self.c, (self.k,1),\n",
    "                                             padding='same').to(device))\n",
    "        self.Plain = nn.Conv2d(int(self.c/2), self.c, (self.k, 1),\n",
    "                               padding='same').to(device)\n",
    "        self.EndConv1 = nn.Conv2d(int(self.c/2), self.c, (1,1)).to(device)\n",
    "        self.EndConv2 = nn.Conv2d(self.c, 2, (1,1)).to(device)\n",
    "        self.Lin1 = nn.Linear(max_len*12*2, 64).to(device)\n",
    "        self.Lin2 = nn.Linear(64, 2).to(device)\n",
    "    \n",
    "    def forward(self, p1, p2):\n",
    "        x = self.InputConv(torch.stack((p1, p2), dim=1))\n",
    "        for i in range(self.n):\n",
    "            x = self.BasicConvs[i](F.glu(F.layer_norm(x, x.shape[1:]), dim=1)) + x\n",
    "        x = self.Plain(F.glu(F.layer_norm(x, x.shape[1:]), dim=1))\n",
    "        for i in range(self.n, 2*self.n):\n",
    "            x = self.BasicConvs[i](F.glu(F.layer_norm(x, x.shape[1:]), dim=1)) + x\n",
    "        x = F.glu(F.layer_norm(x, x.shape[1:]), dim=1)\n",
    "        x = F.dropout(self.EndConv1(x), p=0.5)\n",
    "        x = self.EndConv2(x).flatten(start_dim=1)\n",
    "        x = F.relu(self.Lin1(F.dropout(x, p=0.5)))\n",
    "        x = self.Lin2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "d1zIVvPnZfoN"
   },
   "outputs": [],
   "source": [
    "# loss_fn_name is one of 'BCE', 'Cross', 'KLDiv', 'SoftMargin', or 'MSE'\n",
    "loss_fn_name = 'MSE'\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "c = 256\n",
    "k = 5\n",
    "n = 10\n",
    "model = ConvolutionalClassifier2d(c, k, n)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "dataset = HuRI2d(labs, p1, p2, loss_fn_name)\n",
    "\n",
    "train_test = random_split(dataset, [int(labs.shape[0]*0.8), \n",
    "                                    labs.shape[0]-int(labs.shape[0]*0.8)],\n",
    "                          generator=generator)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_test[0], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(train_test[1], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model and optimize\n",
    "mode = 'max'\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                         mode=mode, factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RV47jFhlZZPu",
    "outputId": "60b0ccb9-6d96-4347-a9b5-ff99cd9b58bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  Test Acc: 52.308\tTrain Loss: 1.001\tTest Loss: 0.946\tTrain Acc: 50.169\tRuntime: 1132.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(train_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[1;32m     16\u001b[0m                 train_data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m probs, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_fn_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCross\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     21\u001b[0m                    train_labels\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "train_loss_tracker = torch.zeros(num_epochs).to(device)\n",
    "test_loss_tracker = torch.zeros(num_epochs).to(device)\n",
    "\n",
    "tic = time.time()\n",
    "te = tic\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_acc = torch.tensor(0).type(torch.float).to(device)\n",
    "    for i, (train_data, train_labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(train_data[0].to(device), \n",
    "                        train_data[1].to(device)).to(device)\n",
    "        probs, preds = torch.max(outputs, dim=1)\n",
    "        train_labels = train_labels.to(device)\n",
    "        if loss_fn_name == 'Cross':\n",
    "            loss = loss_fn(outputs.max(dim=1)[0], \n",
    "                           train_labels.argmax().type(torch.long))\n",
    "        else:\n",
    "            loss = loss_fn(outputs, train_labels)\n",
    "        train_loss_tracker[epoch] += loss / (int(labs.shape[0]*0.8))\n",
    "        train_acc += sum(preds == train_labels.argmax()) / \\\n",
    "                        (int(labs.shape[0]*0.8))\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "    model.eval()\n",
    "    acc = torch.tensor(0).type(torch.float).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (test_data, test_labels) in enumerate(test_loader):\n",
    "            outputs = model(test_data[0].to(device), \n",
    "                            test_data[1].to(device)).to(device)\n",
    "            ps, preds = torch.max(outputs, dim=1)\n",
    "            test_labels = test_labels.to(device)\n",
    "            if loss_fn_name == 'Cross':\n",
    "                test_loss = loss_fn(outputs.max(dim=1)[0], \n",
    "                                    test_labels.argmax().type(torch.long))\n",
    "            else:\n",
    "                test_loss = loss_fn(outputs, test_labels)\n",
    "            test_loss_tracker[epoch] += test_loss / \\\n",
    "                    ((labs.shape[0]-int(labs.shape[0]*0.8)))\n",
    "            acc += sum(preds == test_labels.argmax()) / \\\n",
    "                   (labs.shape[0]-int(labs.shape[0]*0.8))\n",
    "    \n",
    "    scheduler.step(acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}:  Test Acc: {round(acc.item()*100, 3)}', end='')\n",
    "    print(f'\\tTrain Loss: {round(train_loss_tracker[epoch].item(), 3)}', end='')\n",
    "    print(f'\\tTest Loss: {round(test_loss_tracker[epoch].item(), 3)}', end='')\n",
    "    print(f'\\tTrain Acc: {round(train_acc.item()*100, 3)}', end='')\n",
    "    print(f'\\tRuntime: {round(time.time()-te, 0)}')\n",
    "    te = time.time()\n",
    "    \n",
    "toc = time.time()\n",
    "print(f'Training Runtime: {toc-tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
